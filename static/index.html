<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep-Dive Voice Agent</title>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; background-color: #f4f4f9; }
        #status { margin-top: 20px; font-weight: bold; color: #555; }
        button { padding: 15px 30px; font-size: 18px; cursor: pointer; background-color: #007bff; color: white; border: none; border-radius: 5px; transition: background 0.3s; }
        button:hover { background-color: #0056b3; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }
        #response-area { margin-top: 20px; padding: 15px; border: 1px solid #ddd; background: white; width: 80%; max-width: 600px; min-height: 100px; }
    </style>
</head>
<body>

    <h1>üéôÔ∏è Deep-Dive Research Agent</h1>
    <button id="recordBtn">Tap to Speak</button>
    <p id="status">Ready...</p>
    
    <div id="response-area">Response will appear here...</div>

    <script>
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        const responseArea = document.getElementById('response-area');

        // 1. Setup Speech Recognition (Browser Native)
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        
        if (!SpeechRecognition) {
            alert("Your browser does not support Web Speech API. Try Chrome or Edge.");
        } else {
            const recognition = new SpeechRecognition();
            recognition.lang = 'en-US'; 
            recognition.interimResults = false;

            recordBtn.onclick = () => {
                recognition.start();
                status.innerText = "Listening...";
                recordBtn.disabled = true;
            };

            // 2. Capture Result
            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                status.innerText = "Processing...";
                responseArea.innerText = "You said: " + transcript;

                // 3. Send to FastAPI Backend
                try {
                    const response = await fetch("http://127.0.0.1:8000/process-voice", {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify({ text: transcript })
                    });
                    
                    const data = await response.json();
                    
                    // 4. Display & Speak Response
                    responseArea.innerText = "Agent: " + data.reply;
                    speakResponse(data.reply);
                    
                } catch (error) {
                    console.error("Error:", error);
                    status.innerText = "Error connecting to backend.";
                }

                status.innerText = "Ready";
                recordBtn.disabled = false;
            };

            recognition.onerror = (event) => {
                status.innerText = "Error occurred in recognition: " + event.error;
                recordBtn.disabled = false;
            };
        }

        // 5. TTS (Text to Speech) Helper
        function speakResponse(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>
</html>